{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aparnabansal/anaconda/lib/python3.5/site-packages/gensim/utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import TfidfModel\n",
    "from wordcloud import WordCloud\n",
    "from collections import defaultdict\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_common_surface_form(original_corpus, stemmer):\n",
    "    counts = defaultdict(lambda : defaultdict(int))\n",
    "    surface_forms = {} \n",
    "    for document in original_corpus:\n",
    "        for token in document:\n",
    "            stemmed = stemmer.stem(token)\n",
    "            counts[stemmed][token] += 1 \n",
    "    for stemmed, originals in counts.items():\n",
    "        surface_forms[stemmed] = max(originals, key=lambda i: originals[i]) \n",
    "    return surface_forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generateKeywordCloud(category):\n",
    "    # Stemmer for reducing terms to root form\n",
    "    stemmer = PorterStemmer()\n",
    "    # For storing the stemmed tokens\n",
    "    stemmed_corpus = []\n",
    "    # For storing the non-stemmed tokens\n",
    "    original_corpus = []\n",
    "\n",
    "    path = \"./textForms/\" + category.lower()\n",
    "    for file in os.listdir(path):\n",
    "        # Load file contents\n",
    "        contents = open(path+\"/\"+file).read().lower() \n",
    "        contents = ' '.join([word for word in contents.split() if word not in stopwords.words(\"english\")])\n",
    "        contents = \"\".join(l for l in contents if l not in string.punctuation)\n",
    "        # Extract tokens\n",
    "        tokens = word_tokenize(contents)\n",
    "        # Stem tokens\n",
    "        stemmed = [stemmer.stem(token) for token in tokens]\n",
    "        # Store stemmed document\n",
    "        stemmed_corpus.append(stemmed)\n",
    "        # Store original document\n",
    "        original_corpus.append(tokens)\n",
    "    dictionary = Dictionary(stemmed_corpus)\n",
    "    # Get the surface form for each stemmed word\n",
    "    counts = get_common_surface_form(original_corpus, stemmer)\n",
    "    # Convert to vector corpus\n",
    "    vectors = [dictionary.doc2bow(text) for text in stemmed_corpus]\n",
    "    # Train TF-IDF model\n",
    "    tfidf = TfidfModel(vectors, normalize=True)\n",
    "    # Get TF-IDF weights\n",
    "    weights = tfidf[vectors[0]]\n",
    "    # Replace term IDs with human consumable strings\n",
    "    weights = [(counts[dictionary[pair[0]]], pair[1]) for pair in weights]\n",
    "    # Initialize the cloud\n",
    "    wc = WordCloud(\n",
    "        background_color=\"white\",\n",
    "        max_words=2000,\n",
    "        width = 1024,\n",
    "        height = 720,\n",
    "        stopwords=stopwords.words(\"english\")\n",
    "    )\n",
    "    # Generate the cloud\n",
    "    wc.generate_from_frequencies(weights)\n",
    "    # Save the cloud to a file\n",
    "    wc.to_file(\"word_cloud.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generateKeywordCloud('B')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
